{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f5cfdd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc692cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pytz\n",
    "import duckdb\n",
    "import time\n",
    "\n",
    "import requests as rq\n",
    "import json\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import websockets\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db9f59",
   "metadata": {},
   "source": [
    "### Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e82df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads variables from .env file into environment\n",
    "load_dotenv()\n",
    "\n",
    "CG_DEMO_API_KEY = os.getenv(\"CG_DEMO_API_KEY\")\n",
    "if not CG_DEMO_API_KEY:\n",
    "    raise RuntimeError(\"Missing Demo API key in the environment\")\n",
    "\n",
    "CG_PRO_API_KEY = os.getenv(\"CG_PRO_API_KEY\")\n",
    "if not CG_PRO_API_KEY:\n",
    "    raise RuntimeError(\"Missing Pro API key in the environment\")\n",
    "\n",
    "CG_ANALYST_API_KEY = os.getenv(\"CG_ANALYST_API_KEY\")\n",
    "if not CG_ANALYST_API_KEY:\n",
    "    raise RuntimeError(\"Missing Analyst API key in the environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83317fa",
   "metadata": {},
   "source": [
    "### API status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10672c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUB_URL = \"https://api.coingecko.com/api/v3\"\n",
    "PRO_URL = \"https://pro-api.coingecko.com/api/v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d9416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(endpoint, headers, params, URL):\n",
    "\n",
    "    url = \"\".join((URL, endpoint))\n",
    "    response = rq.get(url, headers=headers, params=params)\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except ValueError:\n",
    "        print(\"Invalid JSON response\")\n",
    "        return None\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data, status code {response.status_code}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457cf16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_demo = {\n",
    "           \"accept\": \"application/json\",\n",
    "           \"x-cg-demo-api-key\" : CG_DEMO_API_KEY\n",
    "}\n",
    "\n",
    "use_pro = {\n",
    "         \"accept\": \"application/json\",\n",
    "         \"x-cg-pro-api-key\" : CG_PRO_API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8e0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data, status code 400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2026-01-25T18:40:55.371+00:00',\n",
       " 'error_code': 10010,\n",
       " 'status': {'error_message': 'If you are using Pro API key, please change your root URL from api.coingecko.com to pro-api.coingecko.com  Please refer here for more details: https://docs.coingecko.com/reference/authentication'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"/ping\", use_demo, \"\", PUB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a29a9",
   "metadata": {},
   "source": [
    "### Get new pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6265cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(d, path, default=None):\n",
    "    \"\"\"Safely get a nested dictionary value.\"\"\"\n",
    "    for key in path:\n",
    "        if isinstance(d, dict) and key in d:\n",
    "            d = d[key]\n",
    "        else:\n",
    "            return default\n",
    "    return d\n",
    "\n",
    "def collect_response(list_response):\n",
    "\n",
    "    response_all = []\n",
    "\n",
    "    for response in list_response.get(\"data\", []):\n",
    "        \n",
    "        all_attributes = response.get(\"attributes\", {})\n",
    "        rel = response.get(\"relationships\", {})\n",
    "        \n",
    "        base_token_add = safe_get(rel, [\"base_token\", \"data\", \"id\"], \"NA\")\n",
    "        \n",
    "        # If token_add exists, split it.\n",
    "        token_add = base_token_add.split(\"_\")[1] if base_token_add != \"NA\" and \"_\" in base_token_add else \"NA\"\n",
    "        \n",
    "        temp_dict = dict(\n",
    "            pair = safe_get(all_attributes, [\"name\"], \"NA\"),\n",
    "            pool_created_at = safe_get(all_attributes, [\"pool_created_at\"], \"NA\"),\n",
    "            dex = safe_get(rel, [\"dex\", \"data\", \"id\"], \"NA\"),\n",
    "            network = safe_get(rel, [\"network\", \"data\", \"id\"], \"NA\"),\n",
    "            token_add = token_add,\n",
    "            pool_add = safe_get(all_attributes, [\"address\"], \"NA\"),\n",
    "            fdv_usd = safe_get(all_attributes, [\"fdv_usd\"], \"NA\"),\n",
    "            market_cap_usd = safe_get(all_attributes, [\"market_cap_usd\"], \"NA\"),\n",
    "            daily_volume = safe_get(all_attributes, [\"volume_usd\", \"h24\"], \"NA\"),\n",
    "            daily_price_change = safe_get(all_attributes, [\"price_change_percentage\", \"h24\"], \"NA\"),\n",
    "        )\n",
    "        \n",
    "        response_all.append(temp_dict)\n",
    "\n",
    "    return response_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc640fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_pools(network, sort_by_col, max_pages=None):\n",
    "    \n",
    "    endpoint = f\"/onchain/networks/{network}/new_pools\"\n",
    "    params = {}\n",
    "    newpools_all = []\n",
    "    page_count = 0\n",
    "\n",
    "    # Follow pagination via the response links.next and collect across pages, with an optional max_pages cap.\n",
    "    while True:\n",
    "        pools_list_response = get_response(endpoint, use_pro, params, PRO_URL)\n",
    "        if not pools_list_response:\n",
    "            break\n",
    "\n",
    "        newpools_all.extend(collect_response(pools_list_response))\n",
    "        page_count += 1\n",
    "\n",
    "        if max_pages is not None and page_count >= max_pages:\n",
    "            break\n",
    "\n",
    "        links = pools_list_response.get(\"links\", {})\n",
    "        next_link = links.get(\"next\") if isinstance(links, dict) else None\n",
    "        if not next_link:\n",
    "            break\n",
    "\n",
    "        parsed = urlparse(next_link)\n",
    "        endpoint = parsed.path\n",
    "        params = {k: v[0] for k, v in parse_qs(parsed.query).items()}\n",
    "\n",
    "    df_new_pools = pd.DataFrame(newpools_all)\n",
    "\n",
    "    # Change to local timezone\n",
    "    df_new_pools[\"pool_created_at\"] = pd.to_datetime(df_new_pools[\"pool_created_at\"], utc=True)\n",
    "    df_new_pools[\"pool_created_at\"] = df_new_pools[\"pool_created_at\"].dt.tz_convert(\"Europe/Berlin\")\n",
    "\n",
    "    return df_new_pools[df_new_pools[\"dex\"] == \"pump-fun\"].sort_values(\n",
    "        by=[f\"{sort_by_col}\"], ascending=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b75f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_new_pools(\"solana\", \"pool_created_at\", max_pages = 5).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53927e",
   "metadata": {},
   "source": [
    "### Filter profitable pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pool_response(list_response):\n",
    "\n",
    "    response = list_response.get(\"data\", {})\n",
    "    all_attributes = response.get(\"attributes\", {})\n",
    "    daily_tx = all_attributes[\"transactions\"][\"h24\"]\n",
    "    rel = response[\"relationships\"]\n",
    "    \n",
    "    # Safely extract launchpad_details or default to empty dict\n",
    "    launchpad_details = all_attributes.get(\"launchpad_details\", {})\n",
    "        \n",
    "    response_dict = dict(\n",
    "        pair = all_attributes[\"name\"],\n",
    "        dex = rel[\"dex\"][\"data\"][\"id\"],\n",
    "        token_add = rel[\"base_token\"][\"data\"][\"id\"].split(\"_\")[1],\n",
    "        pool_add = all_attributes[\"address\"],\n",
    "        pool_created_at = all_attributes[\"pool_created_at\"],\n",
    "        fdv_usd = all_attributes[\"fdv_usd\"],\n",
    "        market_cap_usd = all_attributes[\"market_cap_usd\"],\n",
    "        daily_volume = all_attributes[\"volume_usd\"][\"h24\"],\n",
    "        daily_price_change = all_attributes[\"price_change_percentage\"][\"h24\"],\n",
    "        daily_buys = daily_tx[\"buys\"],\n",
    "        daily_sells = daily_tx[\"sells\"],\n",
    "        daily_buyers = daily_tx[\"buyers\"],\n",
    "        daily_sellers = daily_tx[\"sellers\"],\n",
    "        grad_pert = (\n",
    "            launchpad_details.get(\"graduation_percentage\")\n",
    "            if launchpad_details else 0\n",
    "        ),\n",
    "        completed = launchpad_details.get(\"completed\", False),\n",
    "        completed_at = launchpad_details.get(\"completed_at\", None),\n",
    "        dest_pool = launchpad_details.get(\"migrated_destination_pool_address\", None)\n",
    "    )\n",
    "\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c18606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pool_data(network, pool_address):\n",
    "\n",
    "    target_url = f\"/onchain/networks/{network}/pools/{pool_address}\"\n",
    "\n",
    "    pool_list_response = get_response(target_url,\n",
    "                                      use_pro,\n",
    "                                      \"\",\n",
    "                                      PRO_URL)\n",
    "\n",
    "    pool_all = collect_pool_response(pool_list_response)\n",
    "\n",
    "    return pool_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff823b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pool_data(network, num_rows, max_pages):\n",
    "\n",
    "    df_new_pools = get_new_pools(network, \"pool_created_at\", max_pages).head(num_rows)\n",
    "    \n",
    "    all_pool_data = []\n",
    "\n",
    "    for pool_add in df_new_pools[\"pool_add\"]:\n",
    "        pool_data = get_pool_data(network, pool_add)\n",
    "        all_pool_data.append(pool_data)\n",
    "\n",
    "    df = pd.DataFrame(all_pool_data)\n",
    "\n",
    "    df = df.astype({\n",
    "        \"pair\": \"string\",\n",
    "        \"dex\": \"string\",\n",
    "        \"pool_add\": \"string\",\n",
    "        \"token_add\": \"string\",\n",
    "        \"daily_buys\": \"Int64\",\n",
    "        \"daily_sells\": \"Int64\",\n",
    "        \"daily_buyers\": \"Int64\",\n",
    "        \"daily_sellers\": \"Int64\",\n",
    "        \"completed\": \"boolean\",\n",
    "        \"dest_pool\": \"string\",\n",
    "    })\n",
    "\n",
    "    # Numeric columns (coerce invalids to NaN)\n",
    "    for col in [\"fdv_usd\", \"market_cap_usd\", \"daily_volume\", \"daily_price_change\", \"grad_pert\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Timestamps\n",
    "    df[\"pool_created_at\"] = pd.to_datetime(df[\"pool_created_at\"], utc=True, errors=\"coerce\")\n",
    "    df[\"completed_at\"] = pd.to_datetime(df[\"completed_at\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeee2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pools(network, num_rows, max_pages=5):\n",
    "\n",
    "    df_pool_data = collect_pool_data(network, num_rows, max_pages)\n",
    "\n",
    "    # Inspect key metrics such as Fully Diluted Volume (FDV) and age of the pool. We want\n",
    "    # to filter out pools which are older than 10 minutes and have FDV less than $5000.\n",
    "    cutoff = pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(minutes=10)\n",
    "\n",
    "    df_filtered = df_pool_data[\n",
    "                        (df_pool_data[\"pool_created_at\"] >= cutoff) &\n",
    "                        (df_pool_data[\"fdv_usd\"] > 2500)\n",
    "                        ].copy()\n",
    "\n",
    "    # Convert to local timezone\n",
    "    df_filtered[\"pool_created_at\"] = df_filtered[\"pool_created_at\"].dt.tz_convert(\"Europe/Berlin\")\n",
    "    \n",
    "    return df_filtered.sort_values(by=\"daily_volume\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6b58862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze_pools(\"solana\", num_rows=200).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b998d",
   "metadata": {},
   "source": [
    "### Monitor real-time price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2fdfa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_URL = f\"wss://stream.coingecko.com/v1?x_cg_pro_api_key={CG_ANALYST_API_KEY}\"\n",
    "NETWORK_ID = \"solana\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ca850",
   "metadata": {},
   "source": [
    "#### Stream and write to DuckDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cf3c8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d22831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = str(Path.cwd() / \"price_ws_stream.duckdb\")\n",
    "\n",
    "# One connection for writes\n",
    "dbw = duckdb.connect(DB_PATH)\n",
    "\n",
    "db_lock = asyncio.Lock()\n",
    "\n",
    "# Create new table\n",
    "dbw.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS price_stream (\n",
    "    channel_type TEXT,\n",
    "    network_id TEXT,\n",
    "    token_address TEXT,\n",
    "    usd_price DOUBLE,\n",
    "    usd_price_24h_change_percentage DOUBLE,\n",
    "    usd_market_cap DOUBLE,\n",
    "    usd_24h_vol DOUBLE,\n",
    "    last_updated_at TIMESTAMPTZ\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "rename_map = {\n",
    "    \"c\": \"channel_type\",\n",
    "    \"n\": \"network_id\",\n",
    "    \"ta\": \"token_address\",\n",
    "    \"p\": \"usd_price\",\n",
    "    \"pp\": \"usd_price_24h_change_percentage\",\n",
    "    \"m\": \"usd_market_cap\",\n",
    "    \"v\": \"usd_24h_vol\",\n",
    "    \"t\": \"last_updated_at\",\n",
    "}\n",
    "\n",
    "async def stream_token_price_and_write_to_db(TOKEN_ADDRESS):\n",
    "\n",
    "    async with websockets.connect(WS_URL) as ws:\n",
    "        # 1) Subscribe\n",
    "        subscribe_msg = {\n",
    "            \"command\": \"subscribe\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"})\n",
    "        }\n",
    "        await ws.send(json.dumps(subscribe_msg))\n",
    "\n",
    "        # 2) Send message to set tokens\n",
    "        data_payload = {\n",
    "            \"network_id:token_addresses\": [f\"{NETWORK_ID}:{TOKEN_ADDRESS}\"],\n",
    "            \"action\": \"set_tokens\"\n",
    "        }\n",
    "        message_msg = {\n",
    "            \"command\": \"message\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"}),\n",
    "            \"data\": json.dumps(data_payload)\n",
    "        }\n",
    "        await ws.send(json.dumps(message_msg))\n",
    "\n",
    "        # 3) Stream and then write data\n",
    "        while True:\n",
    "            msg = await ws.recv()\n",
    "            payload = json.loads(msg)\n",
    "\n",
    "            # Unwrap if needed\n",
    "            if isinstance(payload, dict) and \"message\" in payload:\n",
    "                data = payload[\"message\"]\n",
    "            else:\n",
    "                data = payload\n",
    "\n",
    "            # Only process if we get valid data\n",
    "            if isinstance(data, dict) and \"c\" in data: \n",
    "\n",
    "                row = {rename_map[k]: payload.get(k) for k in rename_map}\n",
    "\n",
    "                # Convert UNIX seconds to CET/CEST\n",
    "                row[\"last_updated_at\"] = (\n",
    "                    pd.to_datetime(row[\"last_updated_at\"], unit=\"s\", utc=True)\n",
    "                    .tz_convert(\"Europe/Berlin\")\n",
    "                )\n",
    "\n",
    "                #print(row)\n",
    "                async with db_lock:\n",
    "                    dbw.execute(\n",
    "                        \"INSERT INTO price_stream VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "                        [\n",
    "                            row[\"channel_type\"],\n",
    "                            row[\"network_id\"],\n",
    "                            row[\"token_address\"],\n",
    "                            row[\"usd_price\"],\n",
    "                            row[\"usd_price_24h_change_percentage\"],\n",
    "                            row[\"usd_market_cap\"],\n",
    "                            row[\"usd_24h_vol\"],\n",
    "                            row[\"last_updated_at\"],\n",
    "                        ],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f20e11",
   "metadata": {},
   "source": [
    "#### Start background writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "10749af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run after we connect + subscribe and have `ws`\n",
    "#TOKEN_ADDRESS = \"E1uH2rcjNnYWwbNyyHZBUj9uAXwrPaSwY4FG8zWzpump\"\n",
    "\n",
    "df_pools = analyze_pools(\"solana\", num_rows=200).head(5)\n",
    "token_list = df_pools[\"token_add\"].dropna().unique().tolist()\n",
    "\n",
    "tasks = [asyncio.create_task(stream_token_price_and_write_to_db(t)) for t in token_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "600be0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Task pending name='Task-30' coro=<WebSocketCommonProtocol.close_connection() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1289> wait_for=<Task pending name='Task-28' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>>,\n",
       " <Task pending name='Task-21' coro=<stream_token_price_and_write_to_db() running at /tmp/ipykernel_611848/3610194262.py:57> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-31' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>,\n",
       " <Task pending name='Task-22' coro=<stream_token_price_and_write_to_db() running at /tmp/ipykernel_611848/3610194262.py:57> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-32' coro=<WebSocketCommonProtocol.keepalive_ping() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1244> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-23' coro=<stream_token_price_and_write_to_db() running at /tmp/ipykernel_611848/3610194262.py:57> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-33' coro=<WebSocketCommonProtocol.close_connection() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1289> wait_for=<Task pending name='Task-31' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>>,\n",
       " <Task pending name='Task-24' coro=<stream_token_price_and_write_to_db() running at /tmp/ipykernel_611848/3610194262.py:57> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-34' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>,\n",
       " <Task pending name='Task-1' coro=<Kernel.dispatch_queue() running at /home/vikas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py:513> cb=[IOLoop.add_future.<locals>.<lambda>() at /home/vikas/.local/lib/python3.10/site-packages/tornado/ioloop.py:685]>,\n",
       " <Task pending name='Task-25' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>,\n",
       " <Task pending name='Task-35' coro=<WebSocketCommonProtocol.keepalive_ping() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1244> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-26' coro=<WebSocketCommonProtocol.keepalive_ping() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1244> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-36' coro=<WebSocketCommonProtocol.close_connection() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1289> wait_for=<Task pending name='Task-34' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>>,\n",
       " <Task pending name='Task-27' coro=<WebSocketCommonProtocol.close_connection() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1289> wait_for=<Task pending name='Task-25' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>>,\n",
       " <Task pending name='Task-37' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>,\n",
       " <Task pending name='Task-28' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>,\n",
       " <Task pending name='Task-38' coro=<WebSocketCommonProtocol.keepalive_ping() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1244> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-20' coro=<stream_token_price_and_write_to_db() running at /tmp/ipykernel_611848/3610194262.py:57> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-29' coro=<WebSocketCommonProtocol.keepalive_ping() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1244> wait_for=<Future pending cb=[Task.task_wakeup()]>>,\n",
       " <Task pending name='Task-39' coro=<WebSocketCommonProtocol.close_connection() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:1289> wait_for=<Task pending name='Task-37' coro=<WebSocketCommonProtocol.transfer_data() running at /home/vikas/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:955> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Task.task_wakeup(), _wait.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:475]>>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in asyncio.all_tasks() if not t.done()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a415eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task.cancel()\n",
    "#task.done()\n",
    "#task.cancelled()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd216f3",
   "metadata": {},
   "source": [
    "#### Read from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "66bd889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbr = duckdb.connect(DB_PATH)\n",
    "\n",
    "# df = dbr.execute(f\"\"\"\n",
    "#     SELECT * FROM price_stream\n",
    "#     WHERE token_address = '{TOKEN_ADDRESS}'\n",
    "#     ORDER BY last_updated_at DESC\n",
    "#     LIMIT 10\n",
    "# \"\"\").df()\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b89180",
   "metadata": {},
   "source": [
    "#### Trade simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f5199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-25 20:50:50+01:00] 8bYt7xFaxwpH99ZSNxBTmRtZAxjpENUe2K7YgLLhpump monitoring @ 0.00000990 (entry=0.00000990 USD)\n",
      "[2026-01-25 20:50:54+01:00] 8bYt7xFaxwpH99ZSNxBTmRtZAxjpENUe2K7YgLLhpump stop_loss @ 0.00000727 (entry=0.00000990 USD)\n",
      "[2026-01-25 20:50:56+01:00] 8bYt7xFaxwpH99ZSNxBTmRtZAxjpENUe2K7YgLLhpump monitoring @ 0.00000944 (entry=0.00000990 USD)\n",
      "[2026-01-25 20:50:57+01:00] 8bYt7xFaxwpH99ZSNxBTmRtZAxjpENUe2K7YgLLhpump stop_loss @ 0.00000718 (entry=0.00000990 USD)\n",
      "[2026-01-25 20:50:50+01:00] DVXfSkJdKPrsqmqrpB4w4562fQMPYgvqcyLWnAvDpump monitoring @ 0.00000867 (entry=0.00000867 USD)\n",
      "[2026-01-25 20:50:50+01:00] FwH269iTxgriTzr6zMqmWbzwb44e8CWP9U7GAMHPpump monitoring @ 0.00000445 (entry=0.00000445 USD)\n",
      "[2026-01-25 20:50:56+01:00] GWQUfD2wF9f7FXyDthL6vNiHSqZCMojC8MWUrgPipump monitoring @ 0.00000494 (entry=0.00000494 USD)\n",
      "[2026-01-25 20:50:50+01:00] CwYMbQN5tQv8CqPQFeA1nd5Rp5c3qfPbdndcY2kQpump monitoring @ 0.00000391 (entry=0.00000391 USD)\n"
     ]
    }
   ],
   "source": [
    "def trade_status(usd_price, entry):\n",
    "\n",
    "    if usd_price > entry * 1.2:\n",
    "        return \"take_profit\"\n",
    "    if usd_price < entry * 0.8:\n",
    "        return \"stop_loss\"\n",
    "    \n",
    "    return \"monitoring\"\n",
    "\n",
    "# Per-token state\n",
    "state = {t: {\"last_ts\": None, \"entry_price\": None, \"last_status\": None} for t in token_list}\n",
    "\n",
    "dbr = duckdb.connect(DB_PATH)\n",
    "\n",
    "while True:\n",
    "    time.sleep(2)\n",
    "\n",
    "    for token in token_list:\n",
    "        last_ts = state[token][\"last_ts\"]\n",
    "        entry_price = state[token][\"entry_price\"]\n",
    "        last_status = state[token][\"last_status\"]\n",
    "\n",
    "        if last_ts is None:\n",
    "            query = f\"\"\"\n",
    "            SELECT * FROM price_stream\n",
    "            WHERE token_address = '{token}'\n",
    "            ORDER BY last_updated_at ASC\n",
    "            \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "            SELECT * FROM price_stream\n",
    "            WHERE token_address = '{token}'\n",
    "              AND last_updated_at > '{last_ts}'\n",
    "            ORDER BY last_updated_at ASC\n",
    "            \"\"\"\n",
    "\n",
    "        df = dbr.execute(query).df()\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        if entry_price is None:\n",
    "            entry_price = df.iloc[0][\"usd_price\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            status = trade_status(row[\"usd_price\"], entry_price)\n",
    "\n",
    "            price_fmt = f\"{row['usd_price']:.8f}\"\n",
    "            entry_fmt = f\"{entry_price:.8f}\"\n",
    "\n",
    "            if status != last_status:\n",
    "                print(f\"[{row['last_updated_at']}] {token} {status} @ {price_fmt} (entry={entry_fmt} USD)\")\n",
    "                last_status = status\n",
    "\n",
    "            last_ts = row[\"last_updated_at\"]\n",
    "\n",
    "        state[token].update({\"last_ts\": last_ts, \"entry_price\": entry_price, \"last_status\": last_status})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
