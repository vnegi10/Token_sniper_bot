{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f5cfdd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dbc692cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pytz\n",
    "import duckdb\n",
    "import time\n",
    "\n",
    "import requests as rq\n",
    "import json\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import websockets\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import numpy as np\n",
    "import psycopg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db9f59",
   "metadata": {},
   "source": [
    "### Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e82df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads variables from .env file into environment\n",
    "load_dotenv()\n",
    "\n",
    "CG_DEMO_API_KEY = os.getenv(\"CG_DEMO_API_KEY\")\n",
    "if not CG_DEMO_API_KEY:\n",
    "    raise RuntimeError(\"Missing Demo API key in the environment\")\n",
    "\n",
    "CG_PRO_API_KEY = os.getenv(\"CG_PRO_API_KEY\")\n",
    "if not CG_PRO_API_KEY:\n",
    "    raise RuntimeError(\"Missing Pro API key in the environment\")\n",
    "\n",
    "CG_ANALYST_API_KEY = os.getenv(\"CG_ANALYST_API_KEY\")\n",
    "if not CG_ANALYST_API_KEY:\n",
    "    raise RuntimeError(\"Missing Analyst API key in the environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83317fa",
   "metadata": {},
   "source": [
    "### API status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10672c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUB_URL = \"https://api.coingecko.com/api/v3\"\n",
    "PRO_URL = \"https://pro-api.coingecko.com/api/v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d9416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(endpoint, headers, params, URL):\n",
    "\n",
    "    url = \"\".join((URL, endpoint))\n",
    "    response = rq.get(url, headers=headers, params=params)\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except ValueError:\n",
    "        print(\"Invalid JSON response\")\n",
    "        return None\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data, status code {response.status_code}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457cf16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_demo = {\n",
    "           \"accept\": \"application/json\",\n",
    "           \"x-cg-demo-api-key\" : CG_DEMO_API_KEY\n",
    "}\n",
    "\n",
    "use_pro = {\n",
    "         \"accept\": \"application/json\",\n",
    "         \"x-cg-pro-api-key\" : CG_PRO_API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8e0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data, status code 400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2026-01-25T20:11:37.477+00:00',\n",
       " 'error_code': 10010,\n",
       " 'status': {'error_message': 'If you are using Pro API key, please change your root URL from api.coingecko.com to pro-api.coingecko.com  Please refer here for more details: https://docs.coingecko.com/reference/authentication'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"/ping\", use_demo, \"\", PUB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a29a9",
   "metadata": {},
   "source": [
    "### Get new pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6265cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(d, path, default=None):\n",
    "    \"\"\"Safely get a nested dictionary value.\"\"\"\n",
    "    for key in path:\n",
    "        if isinstance(d, dict) and key in d:\n",
    "            d = d[key]\n",
    "        else:\n",
    "            return default\n",
    "    return d\n",
    "\n",
    "def collect_response(list_response):\n",
    "\n",
    "    response_all = []\n",
    "\n",
    "    for response in list_response.get(\"data\", []):\n",
    "        \n",
    "        all_attributes = response.get(\"attributes\", {})\n",
    "        rel = response.get(\"relationships\", {})\n",
    "        \n",
    "        base_token_add = safe_get(rel, [\"base_token\", \"data\", \"id\"], \"NA\")\n",
    "        \n",
    "        # If token_add exists, split it.\n",
    "        token_add = base_token_add.split(\"_\")[1] if base_token_add != \"NA\" and \"_\" in base_token_add else \"NA\"\n",
    "        \n",
    "        temp_dict = dict(\n",
    "            pair = safe_get(all_attributes, [\"name\"], \"NA\"),\n",
    "            pool_created_at = safe_get(all_attributes, [\"pool_created_at\"], \"NA\"),\n",
    "            dex = safe_get(rel, [\"dex\", \"data\", \"id\"], \"NA\"),\n",
    "            network = safe_get(rel, [\"network\", \"data\", \"id\"], \"NA\"),\n",
    "            token_add = token_add,\n",
    "            pool_add = safe_get(all_attributes, [\"address\"], \"NA\"),\n",
    "            fdv_usd = safe_get(all_attributes, [\"fdv_usd\"], \"NA\"),\n",
    "            market_cap_usd = safe_get(all_attributes, [\"market_cap_usd\"], \"NA\"),\n",
    "            daily_volume = safe_get(all_attributes, [\"volume_usd\", \"h24\"], \"NA\"),\n",
    "            daily_price_change = safe_get(all_attributes, [\"price_change_percentage\", \"h24\"], \"NA\"),\n",
    "        )\n",
    "        \n",
    "        response_all.append(temp_dict)\n",
    "\n",
    "    return response_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc640fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_pools(network, sort_by_col, max_pages=None):\n",
    "    \n",
    "    endpoint = f\"/onchain/networks/{network}/new_pools\"\n",
    "    params = {}\n",
    "    newpools_all = []\n",
    "    page_count = 0\n",
    "\n",
    "    # Follow pagination via the response links.next and collect across pages, with an optional max_pages cap.\n",
    "    while True:\n",
    "        pools_list_response = get_response(endpoint, use_pro, params, PRO_URL)\n",
    "        if not pools_list_response:\n",
    "            break\n",
    "\n",
    "        newpools_all.extend(collect_response(pools_list_response))\n",
    "        page_count += 1\n",
    "\n",
    "        if max_pages is not None and page_count >= max_pages:\n",
    "            break\n",
    "\n",
    "        links = pools_list_response.get(\"links\", {})\n",
    "        next_link = links.get(\"next\") if isinstance(links, dict) else None\n",
    "        if not next_link:\n",
    "            break\n",
    "\n",
    "        parsed = urlparse(next_link)\n",
    "        endpoint = parsed.path\n",
    "        params = {k: v[0] for k, v in parse_qs(parsed.query).items()}\n",
    "\n",
    "    df_new_pools = pd.DataFrame(newpools_all)\n",
    "\n",
    "    # Change to local timezone\n",
    "    df_new_pools[\"pool_created_at\"] = pd.to_datetime(df_new_pools[\"pool_created_at\"], utc=True)\n",
    "    df_new_pools[\"pool_created_at\"] = df_new_pools[\"pool_created_at\"].dt.tz_convert(\"Europe/Berlin\")\n",
    "\n",
    "    return df_new_pools[df_new_pools[\"dex\"] == \"pump-fun\"].sort_values(\n",
    "        by=[f\"{sort_by_col}\"], ascending=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b75f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_new_pools(\"solana\", \"pool_created_at\", max_pages = 5).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53927e",
   "metadata": {},
   "source": [
    "### Filter profitable pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pool_response(list_response):\n",
    "\n",
    "    response = list_response.get(\"data\", {})\n",
    "    all_attributes = response.get(\"attributes\", {})\n",
    "    daily_tx = all_attributes[\"transactions\"][\"h24\"]\n",
    "    rel = response[\"relationships\"]\n",
    "    \n",
    "    # Safely extract launchpad_details or default to empty dict\n",
    "    launchpad_details = all_attributes.get(\"launchpad_details\", {})\n",
    "        \n",
    "    response_dict = dict(\n",
    "        pair = all_attributes[\"name\"],\n",
    "        dex = rel[\"dex\"][\"data\"][\"id\"],\n",
    "        token_add = rel[\"base_token\"][\"data\"][\"id\"].split(\"_\")[1],\n",
    "        pool_add = all_attributes[\"address\"],\n",
    "        pool_created_at = all_attributes[\"pool_created_at\"],\n",
    "        fdv_usd = all_attributes[\"fdv_usd\"],\n",
    "        market_cap_usd = all_attributes[\"market_cap_usd\"],\n",
    "        daily_volume = all_attributes[\"volume_usd\"][\"h24\"],\n",
    "        daily_price_change = all_attributes[\"price_change_percentage\"][\"h24\"],\n",
    "        daily_buys = daily_tx[\"buys\"],\n",
    "        daily_sells = daily_tx[\"sells\"],\n",
    "        daily_buyers = daily_tx[\"buyers\"],\n",
    "        daily_sellers = daily_tx[\"sellers\"],\n",
    "        grad_pert = (\n",
    "            launchpad_details.get(\"graduation_percentage\")\n",
    "            if launchpad_details else 0\n",
    "        ),\n",
    "        completed = launchpad_details.get(\"completed\", False),\n",
    "        completed_at = launchpad_details.get(\"completed_at\", None),\n",
    "        dest_pool = launchpad_details.get(\"migrated_destination_pool_address\", None)\n",
    "    )\n",
    "\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c18606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pool_data(network, pool_address):\n",
    "\n",
    "    target_url = f\"/onchain/networks/{network}/pools/{pool_address}\"\n",
    "\n",
    "    pool_list_response = get_response(target_url,\n",
    "                                      use_pro,\n",
    "                                      \"\",\n",
    "                                      PRO_URL)\n",
    "\n",
    "    pool_all = collect_pool_response(pool_list_response)\n",
    "\n",
    "    return pool_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff823b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pool_data(network, num_rows, max_pages):\n",
    "\n",
    "    df_new_pools = get_new_pools(network, \"pool_created_at\", max_pages).head(num_rows)\n",
    "    \n",
    "    all_pool_data = []\n",
    "\n",
    "    for pool_add in df_new_pools[\"pool_add\"]:\n",
    "        pool_data = get_pool_data(network, pool_add)\n",
    "        all_pool_data.append(pool_data)\n",
    "\n",
    "    df = pd.DataFrame(all_pool_data)\n",
    "\n",
    "    df = df.astype({\n",
    "        \"pair\": \"string\",\n",
    "        \"dex\": \"string\",\n",
    "        \"pool_add\": \"string\",\n",
    "        \"token_add\": \"string\",\n",
    "        \"daily_buys\": \"Int64\",\n",
    "        \"daily_sells\": \"Int64\",\n",
    "        \"daily_buyers\": \"Int64\",\n",
    "        \"daily_sellers\": \"Int64\",\n",
    "        \"completed\": \"boolean\",\n",
    "        \"dest_pool\": \"string\",\n",
    "    })\n",
    "\n",
    "    # Numeric columns (coerce invalids to NaN)\n",
    "    for col in [\"fdv_usd\", \"market_cap_usd\", \"daily_volume\", \"daily_price_change\", \"grad_pert\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Timestamps\n",
    "    df[\"pool_created_at\"] = pd.to_datetime(df[\"pool_created_at\"], utc=True, errors=\"coerce\")\n",
    "    df[\"completed_at\"] = pd.to_datetime(df[\"completed_at\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aeee2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pools(network, num_rows, max_pages=5):\n",
    "\n",
    "    df_pool_data = collect_pool_data(network, num_rows, max_pages)\n",
    "\n",
    "    # Inspect key metrics such as Fully Diluted Volume (FDV) and age of the pool. We want\n",
    "    # to filter out pools which are older than 10 minutes and have FDV less than $5000.\n",
    "    cutoff = pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(minutes=10)\n",
    "\n",
    "    df_filtered = df_pool_data[\n",
    "                        (df_pool_data[\"pool_created_at\"] >= cutoff) &\n",
    "                        (df_pool_data[\"fdv_usd\"] > 2500)\n",
    "                        ].copy()\n",
    "\n",
    "    # Convert to local timezone\n",
    "    df_filtered[\"pool_created_at\"] = df_filtered[\"pool_created_at\"].dt.tz_convert(\"Europe/Berlin\")\n",
    "    \n",
    "    return df_filtered.sort_values(by = \"grad_pert\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6b58862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze_pools(\"solana\", num_rows=200).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b998d",
   "metadata": {},
   "source": [
    "### Monitor real-time price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fdfa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_URL = f\"wss://stream.coingecko.com/v1?x_cg_pro_api_key={CG_ANALYST_API_KEY}\"\n",
    "NETWORK_ID = \"solana\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ca850",
   "metadata": {},
   "source": [
    "#### Stream and write to DuckDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cf3c8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5d22831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = str(Path.cwd() / \"price_ws_stream.duckdb\")\n",
    "\n",
    "# One connection for writes\n",
    "dbw = duckdb.connect(DB_PATH)\n",
    "\n",
    "db_lock = asyncio.Lock()\n",
    "\n",
    "# Create new table\n",
    "dbw.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS price_stream (\n",
    "    channel_type TEXT,\n",
    "    network_id TEXT,\n",
    "    token_address TEXT,\n",
    "    usd_price DOUBLE,\n",
    "    usd_price_24h_change_percentage DOUBLE,\n",
    "    usd_market_cap DOUBLE,\n",
    "    usd_24h_vol DOUBLE,\n",
    "    last_updated_at TIMESTAMPTZ\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "rename_map = {\n",
    "    \"c\": \"channel_type\",\n",
    "    \"n\": \"network_id\",\n",
    "    \"ta\": \"token_address\",\n",
    "    \"p\": \"usd_price\",\n",
    "    \"pp\": \"usd_price_24h_change_percentage\",\n",
    "    \"m\": \"usd_market_cap\",\n",
    "    \"v\": \"usd_24h_vol\",\n",
    "    \"t\": \"last_updated_at\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b03b1",
   "metadata": {},
   "source": [
    "##### Single token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4f157598",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_single_token_price_and_write_to_db(TOKEN_ADDRESS):\n",
    "\n",
    "    async with websockets.connect(WS_URL) as ws:\n",
    "        # 1) Subscribe\n",
    "        subscribe_msg = {\n",
    "            \"command\": \"subscribe\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"})\n",
    "        }\n",
    "        await ws.send(json.dumps(subscribe_msg))\n",
    "\n",
    "        # 2) Send message to set tokens\n",
    "        data_payload = {\n",
    "            \"network_id:token_addresses\": [f\"{NETWORK_ID}:{TOKEN_ADDRESS}\"],\n",
    "            \"action\": \"set_tokens\"\n",
    "        }\n",
    "        message_msg = {\n",
    "            \"command\": \"message\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"}),\n",
    "            \"data\": json.dumps(data_payload)\n",
    "        }\n",
    "        await ws.send(json.dumps(message_msg))\n",
    "\n",
    "        # 3) Stream and then write data\n",
    "        while True:\n",
    "            msg = await ws.recv()\n",
    "            payload = json.loads(msg)\n",
    "\n",
    "            # Unwrap if needed\n",
    "            if isinstance(payload, dict) and \"message\" in payload:\n",
    "                data = payload[\"message\"]\n",
    "            else:\n",
    "                data = payload\n",
    "\n",
    "            # Only process if we get valid data\n",
    "            if isinstance(data, dict) and \"c\" in data: \n",
    "\n",
    "                row = {rename_map[k]: payload.get(k) for k in rename_map}\n",
    "\n",
    "                # Convert UNIX seconds to CET/CEST\n",
    "                row[\"last_updated_at\"] = (\n",
    "                    pd.to_datetime(row[\"last_updated_at\"], unit=\"s\", utc=True)\n",
    "                    .tz_convert(\"Europe/Berlin\")\n",
    "                )\n",
    "\n",
    "                #print(row)\n",
    "                async with db_lock:\n",
    "                    dbw.execute(\n",
    "                        \"INSERT INTO price_stream VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "                        [\n",
    "                            row[\"channel_type\"],\n",
    "                            row[\"network_id\"],\n",
    "                            row[\"token_address\"],\n",
    "                            row[\"usd_price\"],\n",
    "                            row[\"usd_price_24h_change_percentage\"],\n",
    "                            row[\"usd_market_cap\"],\n",
    "                            row[\"usd_24h_vol\"],\n",
    "                            row[\"last_updated_at\"],\n",
    "                        ],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68685e18",
   "metadata": {},
   "source": [
    "##### Multiple tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f3c0484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_multiple_token_prices_and_write_to_db(token_addresses):\n",
    "    \n",
    "    async with websockets.connect(WS_URL) as ws:\n",
    "        # 1) Subscribe\n",
    "        subscribe_msg = {\n",
    "            \"command\": \"subscribe\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"})\n",
    "        }\n",
    "        await ws.send(json.dumps(subscribe_msg))\n",
    "\n",
    "        # 2) Send message to set tokens\n",
    "        data_payload = {\n",
    "            \"network_id:token_addresses\": [f\"{NETWORK_ID}:{t}\" for t in token_addresses],\n",
    "            \"action\": \"set_tokens\"\n",
    "        }\n",
    "        message_msg = {\n",
    "            \"command\": \"message\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"}),\n",
    "            \"data\": json.dumps(data_payload)\n",
    "        }\n",
    "        await ws.send(json.dumps(message_msg))\n",
    "\n",
    "        # 3) Stream and then write data\n",
    "        while True:\n",
    "            msg = await ws.recv()\n",
    "            payload = json.loads(msg)\n",
    "\n",
    "            # Debugging: print the raw payload\n",
    "            # print(payload)\n",
    "\n",
    "            if isinstance(payload, dict) and isinstance(payload.get(\"message\"), dict):\n",
    "                data = payload[\"message\"]\n",
    "            else:\n",
    "                data = payload\n",
    "\n",
    "            # Check if we get subscription confirmation\n",
    "            if isinstance(data, dict) and data.get(\"code\") == 2000:\n",
    "                print(data.get(\"message\"))\n",
    "\n",
    "            if isinstance(data, dict) and data.get(\"c\") == \"G1\":\n",
    "                row = {rename_map[k]: data.get(k) for k in rename_map}\n",
    "\n",
    "                row[\"last_updated_at\"] = (\n",
    "                    pd.to_datetime(row[\"last_updated_at\"], unit=\"s\", utc=True)\n",
    "                    .tz_convert(\"Europe/Berlin\")\n",
    "                )\n",
    "\n",
    "                #print(row)\n",
    "\n",
    "                # Insert into DuckDB database\n",
    "                async with db_lock:\n",
    "                    dbw.execute(\n",
    "                        \"INSERT INTO price_stream VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "                        [\n",
    "                            row[\"channel_type\"],\n",
    "                            row[\"network_id\"],\n",
    "                            row[\"token_address\"],\n",
    "                            row[\"usd_price\"],\n",
    "                            row[\"usd_price_24h_change_percentage\"],\n",
    "                            row[\"usd_market_cap\"],\n",
    "                            row[\"usd_24h_vol\"],\n",
    "                            row[\"last_updated_at\"],\n",
    "                        ],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f20e11",
   "metadata": {},
   "source": [
    "#### Start background writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "10749af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run after we connect + subscribe and have `ws`\n",
    "#TOKEN_ADDRESS = \"E1uH2rcjNnYWwbNyyHZBUj9uAXwrPaSwY4FG8zWzpump\"\n",
    "\n",
    "df_pools = analyze_pools(\"solana\", num_rows=200).head(50)\n",
    "token_list = df_pools[\"token_add\"].dropna().unique().tolist()\n",
    "\n",
    "#task = asyncio.create_task(stream_multiple_token_prices_and_write_to_db(token_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833a712",
   "metadata": {},
   "source": [
    "#### Save token list to a separate DuckDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9dbd8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH_1 = str(Path.cwd() / \"token_list.duckdb\")\n",
    "dbw_1 = duckdb.connect(DB_PATH_1)\n",
    "\n",
    "dbw_1.execute(\"DROP TABLE IF EXISTS token_list\")\n",
    "\n",
    "dbw_1.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS token_list (\n",
    "    token_address TEXT PRIMARY KEY\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Insert tokens (ignore duplicates)\n",
    "dbw_1.executemany(\n",
    "    \"INSERT OR IGNORE INTO token_list(token_address) VALUES (?)\",\n",
    "    [(t,) for t in token_list]\n",
    ")\n",
    "\n",
    "dbw_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d2f86fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#await stream_multiple_token_prices_and_write_to_db(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "600be0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[t for t in asyncio.all_tasks() if not t.done()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a415eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task.cancel()\n",
    "#task.done()\n",
    "#task.cancelled()\n",
    "\n",
    "# for task in asyncio.all_tasks():\n",
    "#     task.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd216f3",
   "metadata": {},
   "source": [
    "#### Read from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbr = duckdb.connect(DB_PATH)\n",
    "\n",
    "# df = dbr.execute(f\"\"\"\n",
    "#     SELECT * FROM price_stream\n",
    "#     WHERE token_address = '{TOKEN_ADDRESS}'\n",
    "#     ORDER BY last_updated_at DESC\n",
    "#     LIMIT 10\n",
    "# \"\"\").df()\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "384afc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_type</th>\n",
       "      <th>network_id</th>\n",
       "      <th>token_address</th>\n",
       "      <th>usd_price</th>\n",
       "      <th>usd_price_24h_change_percentage</th>\n",
       "      <th>usd_market_cap</th>\n",
       "      <th>usd_24h_vol</th>\n",
       "      <th>last_updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>BPpTuUX4tsUCpfDrRPpZS9r5ywcW7d97MBZ7ee5UvNLD</td>\n",
       "      <td>3.303173e-06</td>\n",
       "      <td>-18.691821</td>\n",
       "      <td>3303.173184</td>\n",
       "      <td>8780.696740</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>BaWXYapJM5gC1Sh1VCMk4o4Gmm9BmE2AWAugKPmWpump</td>\n",
       "      <td>3.307435e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3307.434717</td>\n",
       "      <td>0.116715</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>3DDMbo11VyKyUqwuFjX8p24D4RMY7VAw8bWEdRddpump</td>\n",
       "      <td>3.299574e-06</td>\n",
       "      <td>-0.268716</td>\n",
       "      <td>3299.574198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>2GXWHWxhp35QTE216mAyNiKAycoQsjN99tjqPkTSpump</td>\n",
       "      <td>3.311087e-06</td>\n",
       "      <td>-4.085711</td>\n",
       "      <td>3311.087259</td>\n",
       "      <td>2289.910436</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>72Z4LQjJmSNKTrePVjKRFzbSWcFbMCaksTL1RFCApump</td>\n",
       "      <td>3.313010e-06</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>6626.019638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>G7WQ3sU6MQgpMWgun8RhFWL4stdqM1wjeg4PEVN8pump</td>\n",
       "      <td>3.308906e-06</td>\n",
       "      <td>-27.376320</td>\n",
       "      <td>3308.905932</td>\n",
       "      <td>6741.624787</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>Agw9Pw6RajwK7UQ3NzhvhhPE6fujYHVFs7jzE7Hopump</td>\n",
       "      <td>4.091856e-06</td>\n",
       "      <td>18.582479</td>\n",
       "      <td>4091.855639</td>\n",
       "      <td>1241.421190</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>44BvVZKRyGLqyFYUxgFdA3mPEZtUcri6gCV8EXKLpump</td>\n",
       "      <td>3.854024e-06</td>\n",
       "      <td>16.710221</td>\n",
       "      <td>3854.024484</td>\n",
       "      <td>5426.326140</td>\n",
       "      <td>2026-01-25 23:31:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>31WoyC5i3q2icrWon3Z1fCRjqCd7BQRXwggwkFVkpump</td>\n",
       "      <td>3.303707e-06</td>\n",
       "      <td>-55.515344</td>\n",
       "      <td>3303.706650</td>\n",
       "      <td>2374.605145</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>HxYQKsxKFVtxK68KhT2HMafzL9S5fx25HhQzKjVpump</td>\n",
       "      <td>6.630899e-07</td>\n",
       "      <td>-80.016950</td>\n",
       "      <td>1326.179859</td>\n",
       "      <td>15.869718</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>kUTK9zioZXk5eudCL7bkcZ2rg3kXHiy5xyUPUpvpump</td>\n",
       "      <td>3.358045e-06</td>\n",
       "      <td>-15.255242</td>\n",
       "      <td>3358.044544</td>\n",
       "      <td>1388.580457</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>Du8mYqjmJTTg5F9jxgNggmBjQ5s8cZ998vBTvLM2pump</td>\n",
       "      <td>3.303426e-06</td>\n",
       "      <td>-6.361733</td>\n",
       "      <td>3303.426315</td>\n",
       "      <td>473.309587</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>G1</td>\n",
       "      <td>solana</td>\n",
       "      <td>CxNBRcPhrs3UvC3HptWvz3aDAZYXNtQe6Cyidzh2pump</td>\n",
       "      <td>3.309633e-06</td>\n",
       "      <td>-9.473559</td>\n",
       "      <td>3309.633467</td>\n",
       "      <td>1558.993001</td>\n",
       "      <td>2026-01-25 23:24:29+01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel_type network_id                                 token_address  \\\n",
       "0            G1     solana  BPpTuUX4tsUCpfDrRPpZS9r5ywcW7d97MBZ7ee5UvNLD   \n",
       "1            G1     solana  BaWXYapJM5gC1Sh1VCMk4o4Gmm9BmE2AWAugKPmWpump   \n",
       "2            G1     solana  3DDMbo11VyKyUqwuFjX8p24D4RMY7VAw8bWEdRddpump   \n",
       "3            G1     solana  2GXWHWxhp35QTE216mAyNiKAycoQsjN99tjqPkTSpump   \n",
       "4            G1     solana  72Z4LQjJmSNKTrePVjKRFzbSWcFbMCaksTL1RFCApump   \n",
       "5            G1     solana  G7WQ3sU6MQgpMWgun8RhFWL4stdqM1wjeg4PEVN8pump   \n",
       "6            G1     solana  Agw9Pw6RajwK7UQ3NzhvhhPE6fujYHVFs7jzE7Hopump   \n",
       "7            G1     solana  44BvVZKRyGLqyFYUxgFdA3mPEZtUcri6gCV8EXKLpump   \n",
       "8            G1     solana  31WoyC5i3q2icrWon3Z1fCRjqCd7BQRXwggwkFVkpump   \n",
       "9            G1     solana   HxYQKsxKFVtxK68KhT2HMafzL9S5fx25HhQzKjVpump   \n",
       "10           G1     solana   kUTK9zioZXk5eudCL7bkcZ2rg3kXHiy5xyUPUpvpump   \n",
       "11           G1     solana  Du8mYqjmJTTg5F9jxgNggmBjQ5s8cZ998vBTvLM2pump   \n",
       "12           G1     solana  CxNBRcPhrs3UvC3HptWvz3aDAZYXNtQe6Cyidzh2pump   \n",
       "\n",
       "       usd_price  usd_price_24h_change_percentage  usd_market_cap  \\\n",
       "0   3.303173e-06                       -18.691821     3303.173184   \n",
       "1   3.307435e-06                         0.000000     3307.434717   \n",
       "2   3.299574e-06                        -0.268716     3299.574198   \n",
       "3   3.311087e-06                        -4.085711     3311.087259   \n",
       "4   3.313010e-06                         0.002522     6626.019638   \n",
       "5   3.308906e-06                       -27.376320     3308.905932   \n",
       "6   4.091856e-06                        18.582479     4091.855639   \n",
       "7   3.854024e-06                        16.710221     3854.024484   \n",
       "8   3.303707e-06                       -55.515344     3303.706650   \n",
       "9   6.630899e-07                       -80.016950     1326.179859   \n",
       "10  3.358045e-06                       -15.255242     3358.044544   \n",
       "11  3.303426e-06                        -6.361733     3303.426315   \n",
       "12  3.309633e-06                        -9.473559     3309.633467   \n",
       "\n",
       "    usd_24h_vol           last_updated_at  \n",
       "0   8780.696740 2026-01-25 23:24:29+01:00  \n",
       "1      0.116715 2026-01-25 23:24:29+01:00  \n",
       "2      0.000000 2026-01-25 23:24:29+01:00  \n",
       "3   2289.910436 2026-01-25 23:24:29+01:00  \n",
       "4      0.000000 2026-01-25 23:24:29+01:00  \n",
       "5   6741.624787 2026-01-25 23:24:29+01:00  \n",
       "6   1241.421190 2026-01-25 23:24:29+01:00  \n",
       "7   5426.326140 2026-01-25 23:31:00+01:00  \n",
       "8   2374.605145 2026-01-25 23:24:29+01:00  \n",
       "9     15.869718 2026-01-25 23:24:29+01:00  \n",
       "10  1388.580457 2026-01-25 23:24:29+01:00  \n",
       "11   473.309587 2026-01-25 23:24:29+01:00  \n",
       "12  1558.993001 2026-01-25 23:24:29+01:00  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_sql = \", \".join(f\"'{t}'\" for t in token_list)\n",
    "\n",
    "dbr = duckdb.connect(DB_PATH)\n",
    "\n",
    "df = dbr.execute(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM price_stream\n",
    "    WHERE token_address IN ({tokens_sql})\n",
    "    QUALIFY row_number() OVER (\n",
    "        PARTITION BY token_address\n",
    "        ORDER BY last_updated_at DESC\n",
    "    ) = 1\n",
    "\"\"\").df()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b89180",
   "metadata": {},
   "source": [
    "#### Trade simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_status(usd_price, entry):\n",
    "\n",
    "    if usd_price > entry * 1.2:\n",
    "        return \"take_profit\"\n",
    "    if usd_price < entry * 0.8:\n",
    "        return \"stop_loss\"\n",
    "    \n",
    "    return \"monitoring\"\n",
    "\n",
    "# Per-token state\n",
    "state = {t: {\"last_ts\": None, \"entry_price\": None, \"last_status\": None} for t in token_list}\n",
    "\n",
    "dbr = duckdb.connect(DB_PATH)\n",
    "\n",
    "# Use ANSI escape codes in the print strings for colors\n",
    "COLORS = {\n",
    "    \"monitoring\": \"\\033[34m\",  # blue\n",
    "    \"stop_loss\": \"\\033[31m\",   # red\n",
    "    \"take_profit\": \"\\033[32m\", # green\n",
    "}\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "while True:\n",
    "    time.sleep(2)\n",
    "\n",
    "    for token in token_list:\n",
    "        last_ts = state[token][\"last_ts\"]\n",
    "        entry_price = state[token][\"entry_price\"]\n",
    "        last_status = state[token][\"last_status\"]\n",
    "\n",
    "        if last_ts is None:\n",
    "            query = f\"\"\"\n",
    "            SELECT * FROM price_stream\n",
    "            WHERE token_address = '{token}'\n",
    "            ORDER BY last_updated_at ASC\n",
    "            \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "            SELECT * FROM price_stream\n",
    "            WHERE token_address = '{token}'\n",
    "              AND last_updated_at > '{last_ts}'\n",
    "            ORDER BY last_updated_at ASC\n",
    "            \"\"\"\n",
    "\n",
    "        df = dbr.execute(query).df()\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        if entry_price is None:\n",
    "            entry_price = df.iloc[0][\"usd_price\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            status = trade_status(row[\"usd_price\"], entry_price)\n",
    "\n",
    "            price_fmt = f\"{row['usd_price']:.8f}\"\n",
    "            entry_fmt = f\"{entry_price:.8f}\"\n",
    "\n",
    "            if status != last_status:\n",
    "                line = f\"[{row['last_updated_at']}] {token} {status} @ {price_fmt} (entry = {entry_fmt} USD)\"\n",
    "                print(f\"{COLORS.get(status, '')}{line}{RESET}\")\n",
    "                last_status = status\n",
    "\n",
    "            last_ts = row[\"last_updated_at\"]\n",
    "\n",
    "        state[token].update({\"last_ts\": last_ts, \"entry_price\": entry_price, \"last_status\": last_status})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3ec78",
   "metadata": {},
   "source": [
    "#### Stream and write to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae338452",
   "metadata": {},
   "source": [
    "##### Connect to database and create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9b1e1be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<psycopg.Cursor [COMMAND_OK] [IDLE] (host=localhost user=vnegi database=price_ws_stream) at 0x764ff597bc10>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PG_DSN = \"postgresql://vnegi:1qaz2wsx@localhost:5432/price_ws_stream\"\n",
    "\n",
    "conn = psycopg.connect(PG_DSN)\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS price_stream (\n",
    "    channel_type TEXT,\n",
    "    network_id TEXT,\n",
    "    token_address TEXT,\n",
    "    usd_price DOUBLE PRECISION,\n",
    "    usd_price_24h_change_percentage DOUBLE PRECISION,\n",
    "    usd_market_cap DOUBLE PRECISION,\n",
    "    usd_24h_vol DOUBLE PRECISION,\n",
    "    last_updated_at TIMESTAMPTZ\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1861d5",
   "metadata": {},
   "source": [
    "##### Multiple tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    \"c\": \"channel_type\",\n",
    "    \"n\": \"network_id\",\n",
    "    \"ta\": \"token_address\",\n",
    "    \"p\": \"usd_price\",\n",
    "    \"pp\": \"usd_price_24h_change_percentage\",\n",
    "    \"m\": \"usd_market_cap\",\n",
    "    \"v\": \"usd_24h_vol\",\n",
    "    \"t\": \"last_updated_at\",\n",
    "}\n",
    "\n",
    "async def stream_token_prices_and_write_to_pg(token_addresses):\n",
    "    async with websockets.connect(WS_URL) as ws:\n",
    "        # subscribe\n",
    "        await ws.send(json.dumps({\n",
    "            \"command\": \"subscribe\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"})\n",
    "        }))\n",
    "\n",
    "        # set tokens\n",
    "        await ws.send(json.dumps({\n",
    "            \"command\": \"message\",\n",
    "            \"identifier\": json.dumps({\"channel\": \"OnchainSimpleTokenPrice\"}),\n",
    "            \"data\": json.dumps({\n",
    "                \"network_id:token_addresses\": [f\"{NETWORK_ID}:{t}\" for t in token_addresses],\n",
    "                \"action\": \"set_tokens\"\n",
    "            })\n",
    "        }))\n",
    "\n",
    "        while True:\n",
    "            msg = await ws.recv()\n",
    "            payload = json.loads(msg)\n",
    "\n",
    "            # Debugging: print the raw payload\n",
    "            # print(payload)\n",
    "\n",
    "            if isinstance(payload, dict) and isinstance(payload.get(\"message\"), dict):\n",
    "                data = payload[\"message\"]\n",
    "            else:\n",
    "                data = payload\n",
    "\n",
    "            # Check if we get subscription confirmation\n",
    "            if isinstance(data, dict) and data.get(\"code\") == 2000:\n",
    "                print(data.get(\"message\"))\n",
    "\n",
    "            # price data\n",
    "            if isinstance(data, dict) and data.get(\"c\") == \"G1\":\n",
    "                row = {rename_map[k]: data.get(k) for k in rename_map}\n",
    "                \n",
    "                row[\"last_updated_at\"] = (\n",
    "                    pd.to_datetime(row[\"last_updated_at\"], unit=\"s\", utc=True)\n",
    "                    .tz_convert(\"Europe/Berlin\")\n",
    "                )\n",
    "\n",
    "                #print(row)\n",
    "\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO price_stream\n",
    "                    (channel_type, network_id, token_address, usd_price,\n",
    "                     usd_price_24h_change_percentage, usd_market_cap, usd_24h_vol, last_updated_at)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\",\n",
    "                    (\n",
    "                        row[\"channel_type\"],\n",
    "                        row[\"network_id\"],\n",
    "                        row[\"token_address\"],\n",
    "                        row[\"usd_price\"],\n",
    "                        row[\"usd_price_24h_change_percentage\"],\n",
    "                        row[\"usd_market_cap\"],\n",
    "                        row[\"usd_24h_vol\"],\n",
    "                        row[\"last_updated_at\"],\n",
    "                    ),\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92982ce8",
   "metadata": {},
   "source": [
    "##### Run writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a42d5ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subscription successful for solana:6YGrm1Z2Syak43NYHQgJKZUgyrjUMK4fARAhPf2ipump\n",
      "Subscription successful for solana:9BKRFE3WfU25GBPTqaksW9U3g8z4kFcYg8G5SwCwpump\n",
      "Subscription successful for solana:9Pv5y1Ry4mSXyWkx4QsxXP5scsMfjZRrSusyh3XHpump\n",
      "Subscription successful for solana:B69YaogsDzpNY6LmkPZPLfjSX2Cuy4chxLHS1A9kCs69\n",
      "Subscription successful for solana:BaFQUZ6Mr1dwqoKQsZwNmeTn4MehnE8hidKFdNCPpump\n",
      "Subscription successful for solana:DVtnMRgJLhpE1b3akJMVxdtqaRtNdhLGUyMRBBQQpump\n",
      "Subscription successful for solana:EFuAb9LQz4ufsEi5cQSDayWE1QEYBg75vji3P3dBpump\n",
      "Subscription successful for solana:GovGE7yizAsYjrjmCnij8LGXd2LSH2dXGGrW8bcFpump\n",
      "Subscription successful for solana:H1UBnFdbZq12YmHVnpgwvJa4dtCYamnfgT8ZbydApump\n",
      "Subscription successful for solana:HNkC2wFcT582FWmtVtGaUQJra77fYP7ZfciQ5HJVG5zv\n",
      "Subscription successful for solana:HPDgJxMnfUnrsHRmhAyEYvx419DhKHYVG3GbkH8Xpump\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[188], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m stream_token_prices_and_write_to_pg(token_list)\n",
      "Cell \u001b[0;32mIn[182], line 31\u001b[0m, in \u001b[0;36mstream_token_prices_and_write_to_pg\u001b[0;34m(token_addresses)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m ws\u001b[38;5;241m.\u001b[39msend(json\u001b[38;5;241m.\u001b[39mdumps({\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnchainSimpleTokenPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m}),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     })\n\u001b[1;32m     28\u001b[0m }))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m ws\u001b[38;5;241m.\u001b[39mrecv()\n\u001b[1;32m     32\u001b[0m     payload \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(msg)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Debugging: print the raw payload\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# print(payload)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/websockets/legacy/protocol.py:548\u001b[0m, in \u001b[0;36mWebSocketCommonProtocol.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pop_message_waiter \u001b[38;5;241m=\u001b[39m pop_message_waiter\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;66;03m# If asyncio.wait() is canceled, it doesn't cancel\u001b[39;00m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# pop_message_waiter and self.transfer_data_task.\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    549\u001b[0m         [pop_message_waiter, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransfer_data_task],\n\u001b[1;32m    550\u001b[0m         return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_COMPLETED,\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pop_message_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:384\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    377\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe explicit passing of coroutine objects to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    378\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.wait() is deprecated since Python 3.8, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduled for removal in Python 3.11.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    382\u001b[0m fs \u001b[38;5;241m=\u001b[39m {ensure_future(f, loop\u001b[38;5;241m=\u001b[39mloop) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs}\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:491\u001b[0m, in \u001b[0;36m_wait\u001b[0;34m(fs, timeout, return_when, loop)\u001b[0m\n\u001b[1;32m    488\u001b[0m     f\u001b[38;5;241m.\u001b[39madd_done_callback(_on_completion)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "await stream_token_prices_and_write_to_pg(token_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
